package cn.itcast.regex.test;

import java.io.BufferedReader;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;
import java.util.List;


/*
 * 网页爬虫：其实就一个程序用于在互联网中获取符合指定规则的数据。 
 * 
 * 爬取邮箱地址。 
 * 
 */
public class RegexTest2 {

	/**
	 * @param args
	 */
	public static void main(String[] args) {

		
		
	}
	
	public static List<String>  getMails() throws IOException{
		
		//1,读取源文件。
		BufferedReader bufr = new BufferedReader(new FileReader("mail.html"));
		
		//2,对读取的数据进行规则的匹配。从中获取符合规则的数据.
		
		//3,将符合规则的数据存储到集合中。
		
	}

}
